{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture of the neural network\n",
    "# Choose an appropriate activation function for each layer\n",
    "# Determine the number of nodes in each layer\n",
    "# Choose an appropriate loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained neural network to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from d2l import torch as d2l\n",
    "from torch.utils.data import DataLoader,random_split,Dataset, SubsetRandomSampler, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, loss_fn, optimizer, device) -> float:\n",
    "    num_batches = len(dataloader) # batches per epoch\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        loss = loss_fn(output,y)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return train_loss/num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch(model, dataloader, loss_fn, device) -> float:\n",
    "    num_batches = len(dataloader) # batches per epoch\n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.inference_mode(mode=True):\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            loss = loss_fn(output, y)\n",
    "            valid_loss += loss.item()\n",
    "    return valid_loss/num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler: torch.optim.lr_scheduler,\n",
    "def train(model, train_loader, valid_loader, loss_fn, optimizer, epochs, device):\n",
    "    # Init the results\n",
    "    result = defaultdict(list)\n",
    "    # Set the model to the device\n",
    "    model.to(device)\n",
    "    # Iterate over the epochs\n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        # Train the model\n",
    "        train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device)\n",
    "        # Validate the model\n",
    "        valid_loss = valid_epoch(model, valid_loader, loss_fn, device)\n",
    "        # Record the loss\n",
    "        result[\"train_loss\"].append(train_loss)\n",
    "        result[\"valid_loss\"].append(valid_loss)\n",
    "        # Adjust the learning rate\n",
    "        # if scheduler:\n",
    "        #     scheduler.step(valid_loss)\n",
    "    # Return the results\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(result):\n",
    "    train_loss = result[\"train_loss\"]\n",
    "    valid_loss = result[\"valid_loss\"]\n",
    "    epochs = range(len(result[\"train_loss\"]))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_loss, label=\"train_loss\")\n",
    "    plt.plot(epochs, valid_loss, label=\"valid_loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "x = torch.tensor(df.drop(['id','y'],axis=1).values,dtype=torch.float32)\n",
    "y = torch.tensor(df['y'].values,dtype=torch.float32)\n",
    "train_data = TensorDataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a381ca5869574c7685245d5faab2fe89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold: 1 Train loss: 0.022605466321110726 Valid loss: 0.024375080059354123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bef0117061a4bf691bce4608626ee4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold: 2 Train loss: 0.02375664930790663 Valid loss: 0.024516614583822396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff482cec1da4191a2c30a8b601ae51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold: 3 Train loss: 0.023327333815395833 Valid loss: 0.023619546483342465\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f058c8e25b4b1c90ffa6f3046da01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold: 4 Train loss: 0.022596201356500388 Valid loss: 0.023605415167716835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0f048cfeed4f38b7145ce8e971cc0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold: 5 Train loss: 0.02421234279870987 Valid loss: 0.02374288898247939\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=K)\n",
    "\n",
    "for fold_i, (train_idx, val_idx) in enumerate(kfold.split(train_data)):\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        valid_sampler = SubsetRandomSampler(val_idx)\n",
    "        train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "        valid_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=valid_sampler)\n",
    "\n",
    "        model = Model()\n",
    "        loss_func = nn.HuberLoss(reduction=\"mean\")\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.5)\n",
    "        # scheduler = scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=50)\n",
    "        # scheduler, \n",
    "        result = train(model, train_loader, valid_loader, loss_fn, optimizer, EPOCHS, device)\n",
    "        print(f\"KFold: {fold_i+1} Train loss: {result['train_loss'][-1]} Valid loss: {result['valid_loss'][-1]}\")\n",
    "        models.append(model.state_dict())\n",
    "        # plot(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('data/test.csv')\n",
    "test_x = torch.tensor(test_data.drop(['id'],axis=1).values,dtype=torch.float32).reshape(-1, 2).to(device)\n",
    "\n",
    "model = Model().to(device)\n",
    "outputs = np.zeros(len(test_x))\n",
    "\n",
    "for model_i in models:\n",
    "    # Load model state dict and set to eval mode\n",
    "    model.load_state_dict(model_i)\n",
    "    model.eval()\n",
    "    # Convert tensor to numpy array\n",
    "    outputs += model(test_x).cpu().detach().numpy().reshape(-1)\n",
    "# Average predictions\n",
    "outputs /= len(models)\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\"id\": range(1, len(outputs) + 1), \"y\": outputs})\n",
    "# Save submission file\n",
    "submission.to_csv(\"./submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
